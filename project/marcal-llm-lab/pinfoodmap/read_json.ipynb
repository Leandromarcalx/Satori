{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    \n",
    "    service = Service('chromedriver.exe')  # Assumes chromedriver.exe is in the same folder\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "driver = start_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106366af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# Load model once\n",
    "print(\"Loading AI model...\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86deba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aebf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your candidate labels\n",
    "candidate_labels = [\"food\", \"other\"]\n",
    "\n",
    "\n",
    "# Create a function to apply\n",
    "def classify_message(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"unknown\"  # or you can return None\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON file\n",
    "json_file_path = 'user_data_json\\\\tiktok\\\\user_data_tiktok.json'\n",
    "\n",
    "# Step 1: Read the JSON\n",
    "with open(json_file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Step 2: Print the data to understand its structure\n",
    "print(\"Loaded JSON data:\")\n",
    "\n",
    "\n",
    "def fix_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.encode('latin1').decode('utf-8')\n",
    "    return text  # if it's not a string, just return it as is\n",
    "\n",
    "def explore_json(data, indent=0):\n",
    "    prefix = '  ' * indent\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            print(f\"{prefix}{key}: {type(value).__name__}\")\n",
    "            explore_json(value, indent + 1)\n",
    "    elif isinstance(data, list) and data:\n",
    "        print(f\"{prefix}[List of {len(data)} items, type {type(data[0]).__name__}]\")\n",
    "        explore_json(data[0], indent + 1)\n",
    "\n",
    "explore_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = data[\"Direct Message\"][\"Direct Messages\"][\"ChatHistory\"][\"Chat History with quimerai:\"]\n",
    "df_zabella = pd.DataFrame(messages).sort_values('Date', ascending = False)\n",
    "df_zabella['Content'] = df_zabella['Content'].apply(fix_text)\n",
    "video_links = df_zabella.loc[df_zabella['Content'].str.contains('video')]\n",
    "lst_video_links = list(dict.fromkeys(video_links['Content'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b705828",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = []\n",
    "\n",
    "print(f\"We'll see {len(lst_video_links)} video descriptions\")\n",
    "for idx, video_url in enumerate(lst_video_links[:100]):\n",
    "    driver.get(video_url)\n",
    "    time.sleep(4)  # Wait for video page to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    desc_tag = soup.find('meta', attrs={'name': 'description'})\n",
    "\n",
    "    if desc_tag:\n",
    "        description = desc_tag['content']\n",
    "        hashtags = [word for word in description.split() if word.startswith('#')]\n",
    "        usernames = [word for word in description.split() if word.startswith('(@')]\n",
    "\n",
    "        data_description.append({\n",
    "            'video_url' : video_url,\n",
    "            'description' : description,\n",
    "            'hashtags' : hashtags,\n",
    "            'usernames' : usernames,\n",
    "        })\n",
    "\n",
    "        print(f\"{idx+1} out of {len(lst_video_links)} collected...\")\n",
    "        # print(f\"üè∑Ô∏è Hashtags: {hashtags}\")\n",
    "        # print(f\"üë• Usernames: {usernames}\")\n",
    "        print(\"-\" * 40)\n",
    "    else:\n",
    "        print('It couldnt collect anything')\n",
    "\n",
    "df_scraped_tiktok = pd.DataFrame(data_description)\n",
    "df_scraped_tiktok['food_related'] = df_scraped_tiktok['description'].progress_apply(classify_message)\n",
    "df_scraped_tiktok.loc[df_scraped_tiktok['food_related'] == 'food'].to_csv('filtered_data.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34477b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_csv('filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efa4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bee5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_videos = []\n",
    "def download_audio_from_tiktok(url, output_dir='downloadaudio'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': f'{output_dir}/%(id)s.%(ext)s',\n",
    "        'ffmpeg_location': 'C:/ffmpeg-2025-04-23-git-25b0a8e295-essentials_build/bin',\n",
    "        'cookiefile': 'tiktok_cookies.txt',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(url, download=True)\n",
    "        audio_path = os.path.join(output_dir, f\"{info['id']}.mp3\")\n",
    "        return audio_path\n",
    "\n",
    "def transcribe_with_huggingface(audio_path, model_name=\"openai/whisper-large-v3\"):\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    pipe = pipeline(\"automatic-speech-recognition\", model=model_name, device=device)\n",
    "    audio_full = AudioSegment.from_mp3(audio_path)\n",
    "    below30sec = audio_full[:29000]\n",
    "    samples = np.array(below30sec.get_array_of_samples()).astype(np.float32)\n",
    "    # Normalize if stereo\n",
    "    if below30sec.channels == 2:\n",
    "        samples = samples.reshape((-1, 2))\n",
    "        samples = samples.mean(axis=1)  # Convert to mono by averaging channels\n",
    "    # Resample to 16kHz using librosa\n",
    "    audio_input = librosa.resample(y=samples, orig_sr=below30sec.frame_rate, target_sr=16000)\n",
    "    result = pipe(audio_input)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def process_tiktok_video(url):\n",
    "    print(f\"Processing: {url}\")\n",
    "    audio_path = download_audio_from_tiktok(url)\n",
    "    transcript = transcribe_with_huggingface(audio_path)\n",
    "    transcribed_videos.append({\n",
    "        'video_url': url,\n",
    "        'transcript': transcript\n",
    "    })\n",
    "    print(f\"Transcript:\\n{transcript}\")\n",
    "    return transcript\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "for url in df_filtered[:3]['video_url']:\n",
    "    process_tiktok_video(url)\n",
    "\n",
    "df_final = pd.DataFrame(transcribed_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.merge(df_filtered, df_final, left_on=['video_url'], right_on=['url'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0442c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = df_complete.drop('url', axis=1)\n",
    "df_complete.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3769d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline = pipeline(\n",
    "    \"ner\", \n",
    "    grouped_entities=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_complete.loc[df_complete['transcript'] != 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste['entities'] = df_teste['transcript'].apply(lambda x: ner_pipeline(x))\n",
    "df_teste['entities_description'] = df_teste['description'].apply(lambda x:ner_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_places(entities):\n",
    "    return [e['word'] for e in entities if e['entity_group'] in ['Local', 'ORG']]\n",
    "\n",
    "df_teste['possible_places'] = df_teste['entities'].apply(extract_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f34d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Descri√ß√µes dos restaurantes\n",
    "descriptions = [\n",
    "    \"Um rol√™ pra sair do √≥bvio em S√£o Paulo. Voc√™s conhecem Nomihodai? √â uma express√£o japonesa que significa tudo que voc√™ puder beber. Basicamente √© um happy hour japon√™s, como em v√°rios bares e karaok√™s do Jap√£o. Agora a gente tem a vers√£o BR. Eu j√° falei do Koi aqui pra voc√™s, que fica na Santa Cec√≠lia. √â bizarro. Pra quem n√£o conhece, √© um bar que tamb√©m tem reserva no formato Makase no andar de cima. E agora eles tem o Nomihodai de ter√ßa a sexta, das 6h √†s 7h30. E como funciona? Tem soju, sake, cerveja e 4 drinks. Voc√™ pode beber √† vontade por 120 reais. Al√©m das bebidas, que eu j√° falo melhor delas.\",\n",
    "    \"Um dos melhores brunchs de S√£o Paulo fica escondido em um bairro residencial e s√≥ quem conhece sabe o quanto √© bom. Tudo aqui √© feito pela casa e um brunch completo sai por menos de R$ 65,00 por pessoa. E vem uma cesta de p√£es artesanais com acompanhamentos, ovos mexidos deliciosos com fatias crocantes de bacon, bolo caseiro do dia, cappuccino italiano ou tradicional brasileiro e a salada de frutas fresquinha. J√° no Alacarte pedimos um toast de avocado com ovos mexidos e presunto.\",\n",
    "    \"A gente foi jantar numa cafeteria japonesa com bonsai no teto, gelato de wasabi, matcha e os pratos mais bem servidos que eu j√° comi em S√£o Paulo. Essa √© a 1908 que fica no para√≠so, literalmente no bairro Par√°. E aqui a gente pediu gyoza e um tempur√° de milho pra entrada. Eu j√° adianto que √© muita coisa se voc√™ vai pedir o prato principal, porque olha isso. Eles s√£o muito bem servidos e eles estavam t√£o bons quanto bonitos. Um yakisoba misto e um yakimichi, esse arroz frito com frango agridoce muito bom. Eu n√£o sei dizer qual que foi o meu favorito, mas vale muito a pena pedir tamb√©m.\"\n",
    "]\n",
    "\n",
    "# Definir as categorias poss√≠veis para os restaurantes\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(descriptions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64426c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cdc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75174391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.json_normalize(data['messages'])\n",
    "df_m.fillna(0, inplace=True)\n",
    "df_m['share.share_text'] = df_m['share.share_text'].apply(fix_text)\n",
    "df_m['sender_name'] = df_m['sender_name'].apply(fix_text)\n",
    "df_m = df_m.loc[df_m['share.link'].str.contains('reel', na=False)].copy().reset_index()\n",
    "df_m['food related'] = df_m['share.share_text'].progress_apply(classify_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7056ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a40aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
